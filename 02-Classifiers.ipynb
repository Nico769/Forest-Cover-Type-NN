{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow import keras\n",
    "from tensorflow import set_random_seed\n",
    "from numpy.random import seed\n",
    "from datetime import datetime\n",
    "\n",
    "# set numpy seed for reproducibility\n",
    "seed(1)\n",
    "# set tf seed for reproducibility\n",
    "set_random_seed(2)\n",
    "#\n",
    "# Turn off GPU usage for tf\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the previously saved dataframe\n",
    "df_covtype_ohe = pd.read_csv(os.path.join(os.getcwd(), 'covtype_ohe.csv'), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_covtype_ohe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df_covtype_ohe):\n",
    "    '''\n",
    "    Split the one hot encoded dataset onto training set and test set\n",
    "    according to UCI's repository guidelines\n",
    "    '''\n",
    "    # First 15120 rows for the training set\n",
    "    X_train = df_covtype_ohe[:15120].copy()\n",
    "    # The last seven colums are the targets\n",
    "    X_train, y_train = X_train.iloc[:, :51], X_train.iloc[:, 51:]\n",
    "    # The remaining rows are for the test set\n",
    "    X_test = df_covtype_ohe[15121:].copy()\n",
    "    X_test, y_test = X_test.iloc[:, :51], X_test.iloc[:, 51:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_covtype_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (15120, 51), X_test: (565891, 51), y_train: (15120, 7), y_test: (565891, 7)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes consistency\n",
    "print(f'X_train: {X_train.shape}, X_test: {X_test.shape}, ' \\\n",
    "      f'y_train: {y_train.shape}, y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's standardize the training set and test set.\n",
    "# Note that we use the training set ONLY to calculate the mean and standard deviation\n",
    "# then normalize the training set \n",
    "# and finally use the (training) mean and standard deviation to normalize the test set.\n",
    "# This ensures no data leakage.\n",
    "\n",
    "def train_test_normalize(X_train, X_test):\n",
    "    '''\n",
    "    Perform standardization on the training set and transforms the\n",
    "    test set accordingly\n",
    "    '''\n",
    "    # The numerical columns we want to normalize\n",
    "    numerical_columns = ['Elevation',\n",
    "                         'Distance_To_Hydrology',\n",
    "                         'Horizontal_Distance_To_Roadways',\n",
    "                         'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
    "                         'Horizontal_Distance_To_Fire_Points']\n",
    "    # Calculate the mean and standard deviation of the training set\n",
    "    X_train_num_cols_mean = X_train[numerical_columns].mean()\n",
    "    X_train_num_cols_std = X_train[numerical_columns].std()\n",
    "    # Perform standardization over the numerical columns of the training set\n",
    "    X_train_std = (X_train[numerical_columns] - X_train_num_cols_mean) / X_train_num_cols_std\n",
    "    # Concatenate side-by-side the normalized training set and the one-hot encoded features\n",
    "    # Note that we index X_train dataframe by the (set) difference of the overall features\n",
    "    # minus the numerical ones\n",
    "    ohe_features = X_train.columns.difference(other=numerical_columns, sort=False)\n",
    "    X_train_std = pd.concat([X_train_std, X_train[ohe_features]], axis=1)\n",
    "    # Perform standardization over the numerical columns of the test set, using the mean and std\n",
    "    # of the training set as discussed earlier\n",
    "    X_test_std = (X_test[numerical_columns] - X_train_num_cols_mean) / X_train_num_cols_std\n",
    "    # Concatenate side-by-side the normalized test set and the one-hot encoded features\n",
    "    X_test_std = pd.concat([X_test_std, X_test[ohe_features]], axis=1)\n",
    "    return X_train_std, X_test_std\n",
    "\n",
    "X_train_std, X_test_std = train_test_normalize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train/test sets to numpy float32 ndarrays\n",
    "# (after doing some research it appears that float32 should be used when using a GPU)\n",
    "X_train_std = X_train_std.to_numpy().astype(np.float32)\n",
    "X_test_std = X_test_std.to_numpy().astype(np.float32)\n",
    "y_train = y_train.to_numpy().astype(np.float32)\n",
    "y_test = y_test.to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the training/validation set splitter.\n",
    "# We'll use it later for the grid-search, performing a 10-fold cross validation\n",
    "# where each validation set is 25% the size of the training set.\n",
    "# This yields 1620 samples per class for the new training set and\n",
    "# 540 samples per class for each validation set.\n",
    "validation_strat = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass KerasClassifier and override fit() method\n",
    "# to fix OOM error when running sklearn GridSearchCV on the GPU\n",
    "class GridKerasClassifier(keras.wrappers.scikit_learn.KerasClassifier):\n",
    "    def fit(self, *args, **kwargs):\n",
    "        # Clear tensorflow session each time fit is invoked\n",
    "        keras.backend.clear_session()\n",
    "        # Use custom configuration for the new session\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        session = tf.Session(config=config)\n",
    "        keras.backend.set_session(session)\n",
    "        super().fit(*args, **kwargs)\n",
    "\n",
    "# Wrapper function which builds the classifier architecture\n",
    "def make_model(n_features=51, n_classes=7, dense_layer_size=120, learning_rate=0.5):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(dense_layer_size, activation='relu', input_dim=n_features))\n",
    "    model.add(keras.layers.Dense(n_classes, activation='softmax'))\n",
    "    sgd = keras.optimizers.SGD(lr=learning_rate) # per il momentum: momentum=0.9\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the Keras neural network onto a scikit Classifier\n",
    "classifier_net = GridKerasClassifier(make_model)\n",
    "\n",
    "# For params tuning see\n",
    "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "\n",
    "# Define the grid search params\n",
    "# uncomment for changing the default number of features and/or classes\n",
    "# for the network. DON'T FORGET TO CHANGE THE TRAINING/TEST SET ACCORDINGLY!\n",
    "# n_features = [X_train_std.shape[1]]\n",
    "# n_classes = [y_train.shape[1]]\n",
    "dense_layer_size = [120]\n",
    "# 0.5 is the best so far\n",
    "learning_rate = [0.5]\n",
    "# 128 seems to work well\n",
    "batch_size = [128]\n",
    "# Try 100, 500, 1000\n",
    "epochs = [10]\n",
    "# Define the grid of parameters \n",
    "param_grid = dict(# n_features=n_features, # uncomment if needed\n",
    "                  # n_classes=n_classes,   # uncomment if needed\n",
    "                  dense_layer_size=dense_layer_size,\n",
    "                  learning_rate=learning_rate,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs)\n",
    "# Initialize the grid search using the nn classifier and the cross-validation\n",
    "# strategy defined above. Since clear_session() is invoked after each CV run,\n",
    "# it's fine to set n_jobs=-1 when running on the GPU.\n",
    "grid = GridSearchCV(estimator=classifier_net,\n",
    "                    param_grid=param_grid,\n",
    "                    n_jobs=-1,\n",
    "                    cv=validation_strat,\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:   21.8s remaining:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   21.9s finished\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0715 07:41:31.182157 140080279652160 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15120/15120 [==============================] - 0s 29us/sample - loss: 0.9379 - acc: 0.6284\n",
      "Epoch 2/10\n",
      "15120/15120 [==============================] - 0s 16us/sample - loss: 0.7166 - acc: 0.6980\n",
      "Epoch 3/10\n",
      "15120/15120 [==============================] - 0s 16us/sample - loss: 0.6723 - acc: 0.7168\n",
      "Epoch 4/10\n",
      "15120/15120 [==============================] - 0s 15us/sample - loss: 0.6410 - acc: 0.7309\n",
      "Epoch 5/10\n",
      "15120/15120 [==============================] - 0s 16us/sample - loss: 0.6214 - acc: 0.7410\n",
      "Epoch 6/10\n",
      "15120/15120 [==============================] - 0s 16us/sample - loss: 0.6056 - acc: 0.7438\n",
      "Epoch 7/10\n",
      "15120/15120 [==============================] - 0s 16us/sample - loss: 0.5891 - acc: 0.7563\n",
      "Epoch 8/10\n",
      "15120/15120 [==============================] - 0s 15us/sample - loss: 0.5798 - acc: 0.7571\n",
      "Epoch 9/10\n",
      "15120/15120 [==============================] - 0s 16us/sample - loss: 0.5748 - acc: 0.7620\n",
      "Epoch 10/10\n",
      "15120/15120 [==============================] - 0s 17us/sample - loss: 0.5591 - acc: 0.7700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=10, test_size=0.25,\n",
       "            train_size=None),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=<__main__.GridKerasClassifier object at 0x7f66f006cd30>,\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'batch_size': [128], 'dense_layer_size': [120],\n",
       "                         'epochs': [10], 'learning_rate': [0.5]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run grid search\n",
    "# THIS CELL IS TIME CONSUMING, BE AWARE OF THAT!\n",
    "grid.fit(X_train_std, y_train)\n",
    "# Store the best model in the current dir\n",
    "#now = datetime.now()\n",
    "#timestamp = now.strftime('%b-%d-%Y_%H%M')\n",
    "#best_model_fname = f'hidden{dense_layer_size}_epochs{epochs}_{timestamp}.hdf5'\n",
    "#best_model_path = os.path.join(os.getcwd(), best_model_fname)\n",
    "#keras.models.save_model(model=grid.best_estimator_.model,\n",
    "#                        filepath=best_model_path,\n",
    "#                        save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores: 0.7458 using {'batch_size': 128, 'dense_layer_size': 120, 'epochs': 10, 'learning_rate': 0.5}\n",
      "\n",
      "Mean: 0.7458 +- 0.013395 with: {'batch_size': 128, 'dense_layer_size': 120, 'epochs': 10, 'learning_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Print the best scores defined earlier for the grid search and its model params\n",
    "print(f'Best scores: {grid.best_score_:.4f} using {grid.best_params_}', end='\\n\\n')\n",
    "# Get the mean of each score for each cross-validation run\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "# Get the standard dev of each score for each cross-validation run\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "# Get the model params for each cross-validation run\n",
    "params = grid.cv_results_['params']\n",
    "# Loop through means, stds, params and print\n",
    "# one line for each cross-validation run\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f'Mean: {mean:.4f} +- {stdev:.6f} with: {param}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Do some cleanup\n",
    "del grid\n",
    "del classifier_net\n",
    "keras.backend.clear_session()\n",
    "keras.backend.set_session(tf.Session())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# For the best estimator found, compute cross-validated training and test scores\n",
    "# for different training set sizes.\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=grid.best_estimator_,\n",
    "                                                        X=X_train_std,\n",
    "                                                        y=y_train,\n",
    "                                                        cv=validation_strat,\n",
    "                                                        n_jobs=-1,\n",
    "                                                        verbose=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def plot_learning_curve(train_sizes, train_scores, test_scores, title, alpha=0.1):\n",
    "    '''\n",
    "    Plot the scores computed by learning_curve.\n",
    "    The x axis shows the different number of training set size picked during\n",
    "    learning_curve cross-validation while the y axis shows the score of the estimator\n",
    "    '''\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "    plt.figure()\n",
    "    plt.plot(train_sizes, train_mean, label='train score', color='blue', marker='o')\n",
    "    plt.fill_between(train_sizes, train_mean + train_std,\n",
    "                     train_mean - train_std, color='blue', alpha=alpha)\n",
    "    plt.plot(train_sizes, test_mean, label='test score', color='red', marker='o')\n",
    "\n",
    "    plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, color='red', alpha=alpha)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Number of training points')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(ls='--')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_learning_curve(train_sizes, train_scores, test_scores, title='Learning curve')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Run this cell if you already have a trained model\n",
    "#loaded_model = tf.keras.models.load_model(best_model_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Now that the grid search is done\n",
    "# let's perform retrain the best model performing 10-fold cross validation.\n",
    "# Finally, training and validation accuracies will be plotted\n",
    "\n",
    "# Wrapper function which builds the best classifier architecture\n",
    "# TODO: refactor for passing best model params\n",
    "def make_best_model(n_features=51, n_classes=7, dense_layer_size=120, learning_rate=0.5):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(dense_layer_size, activation='relu', input_dim=n_features))\n",
    "    model.add(keras.layers.Dense(n_classes, activation='softmax'))\n",
    "    sgd = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Using plain KerasClassifier since our subclass failed returning History object\n",
    "best_model = make_best_model()\n",
    "cv_train_acc = []\n",
    "cv_val_acc = []\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=1)\n",
    "for train_index, valid_index in sss.split(X_train_std, y_train):\n",
    "    X_train_std_minus_validation = X_train_std[train_index]\n",
    "    X_validation = X_train_std[valid_index]\n",
    "    y_train_minus_validation = y_train[train_index]\n",
    "    y_validation = y_train[valid_index]\n",
    "    history = best_model.fit(X_train_std_minus_validation,\n",
    "                             y_train_minus_validation,\n",
    "                             epochs=20,\n",
    "                             batch_size=128,\n",
    "                             validation_data=(X_validation, y_validation),\n",
    "                             verbose=0)\n",
    "    cv_train_acc.append(history.history['acc'])\n",
    "    cv_val_acc.append(history.history['val_acc'])\n",
    "\n",
    "# For each epoch, k=10 metrics are computed. Take the mean, for each metric, to plot it later.\n",
    "avg_cv_train_acc = [np.mean([x[i] for x in cv_train_acc]) for i in range(20)]\n",
    "avg_cv_val_acc = [np.mean([x[i] for x in cv_val_acc]) for i in range(20)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Plot training/validation accuracy vs number of epochs for the 10-fold cross validated model\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(avg_cv_train_acc) + 1), avg_cv_train_acc, 'bo', label='Training acc')\n",
    "plt.plot(range(1, len(avg_cv_val_acc) + 1), avg_cv_val_acc, 'b', label='Validation acc')\n",
    "# plt.ylim(0, 1)\n",
    "plt.title('Best model train/val accuracy - 10-fold cv')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# When we are satisfied about the best model\n",
    "# run predict on the test set.\n",
    "y_pred = best_model.predict(X_test_std)\n",
    "# Reverse one-hot encoding (i.e going back to categorical variables) for the predicted targets.\n",
    "# Note that argmax return indexes starting from 0, hence add 1.\n",
    "y_pred_cat = np.argmax(y_pred, axis=1) + 1\n",
    "# Do the same for the true targets\n",
    "y_true_cat = np.argmax(y_test, axis=1) + 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Now that we have y_pred and y_true, we can use sklearn.metrics for precision, recall and f1-score metrics\n",
    "target_names = ['Spruce/Fir', 'Lodgepole Pine',\n",
    "                'Ponderosa Pine', 'Cottonwood/Willow',\n",
    "                'Aspen', 'Douglas-fir', 'Krummholz']\n",
    "\n",
    "print(classification_report(y_true_cat,\n",
    "                            y_pred_cat,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Comptue the non normalized confusion matrix\n",
    "cm = confusion_matrix(y_true_cat, y_pred_cat)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# And the normalized confusion matrix.\n",
    "# See: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "norm_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(norm_cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
