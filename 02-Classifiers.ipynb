{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow import keras\n",
    "from tensorflow import set_random_seed\n",
    "from numpy.random import seed\n",
    "from datetime import datetime\n",
    "\n",
    "# set numpy seed for reproducibility\n",
    "seed(1)\n",
    "# set tf seed for reproducibility\n",
    "set_random_seed(2)\n",
    "#\n",
    "# Turn off GPU usage for tf\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the previously saved dataframe\n",
    "df_covtype_ohe = pd.read_csv(os.path.join(os.getcwd(), 'covtype_ohe.csv'), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_covtype_ohe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df_covtype_ohe):\n",
    "    '''\n",
    "    Split the one hot encoded dataset onto training set and test set\n",
    "    according to UCI's repository guidelines\n",
    "    '''\n",
    "    # First 15120 rows for the training set\n",
    "    X_train = df_covtype_ohe[:15120].copy()\n",
    "    # The last seven colums are the targets\n",
    "    X_train, y_train = X_train.iloc[:, :51], X_train.iloc[:, 51:]\n",
    "    # The remaining rows are for the test set\n",
    "    X_test = df_covtype_ohe[15121:].copy()\n",
    "    X_test, y_test = X_test.iloc[:, :51], X_test.iloc[:, 51:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_covtype_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shapes consistency\n",
    "print(f'X_train: {X_train.shape}, X_test: {X_test.shape}, ' \\\n",
    "      f'y_train: {y_train.shape}, y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's standardize the training set and test set.\n",
    "# Note that we use the training set ONLY to calculate the mean and standard deviation\n",
    "# then normalize the training set \n",
    "# and finally use the (training) mean and standard deviation to normalize the test set.\n",
    "# This ensures no data leakage.\n",
    "\n",
    "def train_test_normalize(X_train, X_test):\n",
    "    '''\n",
    "    Perform standardization on the training set and transforms the\n",
    "    test set accordingly\n",
    "    '''\n",
    "    # The numerical columns we want to normalize\n",
    "    numerical_columns = ['Elevation',\n",
    "                         'Distance_To_Hydrology',\n",
    "                         'Horizontal_Distance_To_Roadways',\n",
    "                         'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
    "                         'Horizontal_Distance_To_Fire_Points']\n",
    "    # Calculate the mean and standard deviation of the training set\n",
    "    X_train_num_cols_mean = X_train[numerical_columns].mean()\n",
    "    X_train_num_cols_std = X_train[numerical_columns].std()\n",
    "    # Perform standardization over the numerical columns of the training set\n",
    "    X_train_std = (X_train[numerical_columns] - X_train_num_cols_mean) / X_train_num_cols_std\n",
    "    # Concatenate side-by-side the normalized training set and the one-hot encoded features\n",
    "    # Note that we index X_train dataframe by the (set) difference of the overall features\n",
    "    # minus the numerical ones\n",
    "    ohe_features = X_train.columns.difference(other=numerical_columns, sort=False)\n",
    "    X_train_std = pd.concat([X_train_std, X_train[ohe_features]], axis=1)\n",
    "    # Perform standardization over the numerical columns of the test set, using the mean and std\n",
    "    # of the training set as discussed earlier\n",
    "    X_test_std = (X_test[numerical_columns] - X_train_num_cols_mean) / X_train_num_cols_std\n",
    "    # Concatenate side-by-side the normalized test set and the one-hot encoded features\n",
    "    X_test_std = pd.concat([X_test_std, X_test[ohe_features]], axis=1)\n",
    "    return X_train_std, X_test_std\n",
    "\n",
    "X_train_std, X_test_std = train_test_normalize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train/test sets to numpy float32 ndarrays\n",
    "# (after doing some research it appears that float32 should be used when using a GPU)\n",
    "X_train_std = X_train_std.to_numpy().astype(np.float32)\n",
    "X_test_std = X_test_std.to_numpy().astype(np.float32)\n",
    "y_train = y_train.to_numpy().astype(np.float32)\n",
    "y_test = y_test.to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the training/validation set splitter.\n",
    "# We'll use it later for the grid-search, performing a 10-fold cross validation\n",
    "# where each validation set is 25% the size of the training set.\n",
    "# This yields 1620 samples per class for the new training set and\n",
    "# 540 samples per class for each validation set.\n",
    "validation_strat = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass KerasClassifier and override fit() method\n",
    "# to fix OOM error when running sklearn GridSearchCV on the GPU\n",
    "class GridKerasClassifier(keras.wrappers.scikit_learn.KerasClassifier):\n",
    "    def fit(self, *args, **kwargs):\n",
    "        # Clear tensorflow session each time fit is invoked\n",
    "        keras.backend.clear_session()\n",
    "        # Use custom configuration for the new session\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        session = tf.Session(config=config)\n",
    "        keras.backend.set_session(session)\n",
    "        super().fit(*args, **kwargs)\n",
    "\n",
    "# Wrapper function which builds the classifier architecture\n",
    "def make_model(hidden_layers=1, h1_size=120, h2_size=1,\n",
    "               n_features=51, n_classes=7, learning_rate=0.5, momentum=0.1):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(h1_size, activation='relu', input_dim=n_features))\n",
    "    if hidden_layers > 1:\n",
    "        for i in range(hidden_layers):\n",
    "            # Add multiple hidden layers after the first one.\n",
    "            model.add(keras.layers.Dense(h2_size, activation='relu'))\n",
    "    model.add(keras.layers.Dense(n_classes, activation='softmax'))\n",
    "    sgd = keras.optimizers.SGD(lr=learning_rate, momentum=momentum)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the Keras neural network onto a scikit Classifier\n",
    "classifier_net = GridKerasClassifier(make_model)\n",
    "\n",
    "# For params tuning see\n",
    "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "\n",
    "# Define the grid search params\n",
    "# uncomment for changing the default number of features and/or classes\n",
    "# for the network. DON'T FORGET TO CHANGE THE TRAINING/TEST SET ACCORDINGLY!\n",
    "# n_features = [X_train_std.shape[1]]\n",
    "# n_classes = [y_train.shape[1]]\n",
    "hidden_layers = [2]\n",
    "h1_size = [30]\n",
    "h2_size = [15]\n",
    "# 0.5 is the best so far\n",
    "learning_rate = [0.5]\n",
    "momentum = [0.1]\n",
    "# 128 seems to work well\n",
    "batch_size = [128]\n",
    "# Try 100, 500, 1000\n",
    "epochs = [1000]\n",
    "# Define the grid of parameters \n",
    "param_grid = dict(# n_features=n_features, # uncomment if needed\n",
    "                  # n_classes=n_classes,   # uncomment if needed\n",
    "                  hidden_layers=hidden_layers,\n",
    "                  h1_size=h1_size,\n",
    "                  h2_size=h2_size,\n",
    "                  learning_rate=learning_rate,\n",
    "                  momentum=momentum,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs)\n",
    "# Initialize the grid search using the nn classifier and the cross-validation\n",
    "# strategy defined above. Since clear_session() is invoked after each CV run,\n",
    "# it's fine to set n_jobs=-1 when running on the GPU.\n",
    "grid = GridSearchCV(estimator=classifier_net,\n",
    "                    param_grid=param_grid,\n",
    "                    n_jobs=-1,\n",
    "                    cv=validation_strat,\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run grid search\n",
    "# THIS CELL IS TIME CONSUMING, BE AWARE OF THAT!\n",
    "grid.fit(X_train_std, y_train)\n",
    "# Store the best model in the current dir\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime('%b-%d-%Y_%H%M')\n",
    "best_gr_model_params = grid.best_params_\n",
    "best_gr_model_hlyrs = best_gr_model_params['hidden_layers']\n",
    "best_gr_model_h1size = best_gr_model_params['h1_size']\n",
    "best_gr_model_h2size = best_gr_model_params['h2_size']\n",
    "best_gr_model_epochs = best_gr_model_params['epochs']\n",
    "best_gr_model_bs = best_gr_model_params['batch_size']\n",
    "best_gr_model_mom = best_gr_model_params['momentum']\n",
    "best_model_fname = f'hlyrs{best_gr_model_hlyrs}_h1size{best_gr_model_h1size}_h2size{best_gr_model_h2size}' \\\n",
    "                   f'_epochs{best_gr_model_epochs}_bsize{best_gr_model_bs}_mom{best_gr_model_mom}_{timestamp}.hdf5'\n",
    "best_model_path = os.path.join(os.getcwd(), best_model_fname)\n",
    "keras.models.save_model(model=grid.best_estimator_.model,\n",
    "                        filepath=best_model_path,\n",
    "                        save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the best scores defined earlier for the grid search and its model params\n",
    "print(f'Best scores: {grid.best_score_:.4f} using {grid.best_params_}', end='\\n\\n')\n",
    "# Get the mean of each score for each cross-validation run\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "# Get the standard dev of each score for each cross-validation run\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "# Get the model params for each cross-validation run\n",
    "params = grid.cv_results_['params']\n",
    "# Loop through means, stds, params and print\n",
    "# one line for each cross-validation run\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f'Mean: {mean:.4f} +- {stdev:.6f} with: {param}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Do some cleanup\n",
    "del grid\n",
    "del classifier_net\n",
    "keras.backend.clear_session()\n",
    "keras.backend.set_session(tf.Session())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# For the best estimator found, compute cross-validated training and test scores\n",
    "# for different training set sizes.\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=grid.best_estimator_,\n",
    "                                                        X=X_train_std,\n",
    "                                                        y=y_train,\n",
    "                                                        cv=validation_strat,\n",
    "                                                        n_jobs=-1,\n",
    "                                                        verbose=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def plot_learning_curve(train_sizes, train_scores, test_scores, title, alpha=0.1):\n",
    "    '''\n",
    "    Plot the scores computed by learning_curve.\n",
    "    The x axis shows the different number of training set size picked during\n",
    "    learning_curve cross-validation while the y axis shows the score of the estimator\n",
    "    '''\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "    plt.figure()\n",
    "    plt.plot(train_sizes, train_mean, label='train score', color='blue', marker='o')\n",
    "    plt.fill_between(train_sizes, train_mean + train_std,\n",
    "                     train_mean - train_std, color='blue', alpha=alpha)\n",
    "    plt.plot(train_sizes, test_mean, label='test score', color='red', marker='o')\n",
    "\n",
    "    plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, color='red', alpha=alpha)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Number of training points')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(ls='--')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_learning_curve(train_sizes, train_scores, test_scores, title='Learning curve')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Run this cell if you already have a trained model\n",
    "#loaded_model = tf.keras.models.load_model(best_model_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Now that the grid search is done\n",
    "# let's perform retrain the best model performing 10-fold cross validation.\n",
    "# Finally, training and validation accuracies will be plotted\n",
    "\n",
    "# Wrapper function which builds the best classifier architecture\n",
    "# TODO: refactor for passing best model params\n",
    "def make_best_model(n_features=51, n_classes=7, dense_layer_size=120, learning_rate=0.5):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(dense_layer_size, activation='relu', input_dim=n_features))\n",
    "    model.add(keras.layers.Dense(n_classes, activation='softmax'))\n",
    "    sgd = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Using plain KerasClassifier since our subclass failed returning History object\n",
    "best_model = make_best_model()\n",
    "cv_train_acc = []\n",
    "cv_val_acc = []\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=1)\n",
    "for train_index, valid_index in sss.split(X_train_std, y_train):\n",
    "    X_train_std_minus_validation = X_train_std[train_index]\n",
    "    X_validation = X_train_std[valid_index]\n",
    "    y_train_minus_validation = y_train[train_index]\n",
    "    y_validation = y_train[valid_index]\n",
    "    history = best_model.fit(X_train_std_minus_validation,\n",
    "                             y_train_minus_validation,\n",
    "                             epochs=20,\n",
    "                             batch_size=128,\n",
    "                             validation_data=(X_validation, y_validation),\n",
    "                             verbose=0)\n",
    "    cv_train_acc.append(history.history['acc'])\n",
    "    cv_val_acc.append(history.history['val_acc'])\n",
    "\n",
    "# For each epoch, k=10 observations per metric are computed.\n",
    "# For example, cv_train_acc shape is (n_kfolds, n_epochs).\n",
    "# Thus, take the mean of each column to plot the evolution of train/val acc\n",
    "# over the number of epochs\n",
    "avg_cv_train_acc = np.mean(cv_train_acc, axis=1)\n",
    "avg_cv_val_acc = np.mean(cv_val_acc, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Plot training/validation accuracy vs number of epochs for the 10-fold cross validated model\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(avg_cv_train_acc) + 1), avg_cv_train_acc, 'bo', label='Training acc')\n",
    "plt.plot(range(1, len(avg_cv_val_acc) + 1), avg_cv_val_acc, 'b', label='Validation acc')\n",
    "# plt.ylim(0, 1)\n",
    "plt.title('Best model train/val accuracy - 10-fold cv')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid()\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# When we are satisfied about the best model\n",
    "# run predict on the test set.\n",
    "y_pred = best_model.predict(X_test_std)\n",
    "# Reverse one-hot encoding (i.e going back to categorical variables) for the predicted targets.\n",
    "# Note that argmax return indexes starting from 0, hence add 1.\n",
    "y_pred_cat = np.argmax(y_pred, axis=1) + 1\n",
    "# Do the same for the true targets\n",
    "y_true_cat = np.argmax(y_test, axis=1) + 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Now that we have y_pred and y_true, we can use sklearn.metrics for precision, recall and f1-score metrics\n",
    "target_names = ['Spruce/Fir', 'Lodgepole Pine',\n",
    "                'Ponderosa Pine', 'Cottonwood/Willow',\n",
    "                'Aspen', 'Douglas-fir', 'Krummholz']\n",
    "\n",
    "print(classification_report(y_true_cat,\n",
    "                            y_pred_cat,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Comptue the non normalized confusion matrix\n",
    "cm = confusion_matrix(y_true_cat, y_pred_cat)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# And the normalized confusion matrix.\n",
    "# See: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "norm_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(norm_cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
